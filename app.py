# Import library and load OpenAI key
import os, re, io
from typing import Dict, Any, List
from pathlib import Path

from chromadb.config import Settings
from dotenv import load_dotenv
load_dotenv(override=True)  

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.runnables import RunnableLambda
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.documents import Document
from langchain_chroma import Chroma
from langchain_core.messages import SystemMessage, HumanMessage, BaseMessage

# ========== ENV ==========
OPENAI__API_KEY = os.getenv("OPENAI__API_KEY")
OPENAI__EMBEDDING_MODEL = os.getenv("OPENAI__EMBEDDING_MODEL")
OPENAI__MODEL_NAME = os.getenv("OPENAI__MODEL_NAME")
OPENAI__TEMPERATURE = os.getenv("OPENAI__TEMPERATURE")

llm = ChatOpenAI(
    api_key=OPENAI__API_KEY,
    model_name=OPENAI__MODEL_NAME,
    temperature=float(OPENAI__TEMPERATURE) if OPENAI__TEMPERATURE else 0
)

# ===== VectorDB + PDF Processing =====

VECTORDB_PATH = r"./vectordb_storage"  
os.makedirs(VECTORDB_PATH, exist_ok=True)  

emb = OpenAIEmbeddings(api_key=OPENAI__API_KEY, model=OPENAI__EMBEDDING_MODEL)

vectordb = Chroma(
    embedding_function=emb,
    persist_directory=VECTORDB_PATH,
    client_settings=Settings(
        anonymized_telemetry=False,
        persist_directory=VECTORDB_PATH
    )
)
retriever = vectordb.as_retriever(search_kwargs={"k": 10})

# ---- PDF Processing Functions ----
def read_pdf_bytes_from_path(path: str) -> bytes:
    """ƒê·ªçc file PDF th√†nh bytes"""
    with open(path, "rb") as f:
        return f.read()

def extract_pdf_text(pdf_bytes: bytes) -> str:
    """Tr√≠ch xu·∫•t text t·ª´ PDF bytes"""
    from pypdf import PdfReader
    reader = PdfReader(io.BytesIO(pdf_bytes))
    texts = []
    for page in reader.pages:
        texts.append(page.extract_text() or "")
    return "\n".join(texts).strip()

def chunk_text(s: str, chunk_size: int = 1000, overlap: int = 200) -> List[str]:
    """Chia text th√†nh c√°c chunk nh·ªè"""
    s = s.strip()
    if not s: return []
    chunks, start, n = [], 0, len(s)
    while start < n:
        end = min(n, start + chunk_size)
        chunks.append(s[start:end])
        if end == n: break
        start = max(0, end - overlap)
    return chunks

# --- ƒê∆Ø·ªúNG D·∫™N PDF C·ªê ƒê·ªäNH ---
PDF_PATH = r"C:\Users\tabao\Downloads\luat_lao_dong\45_2019_QH14_333670.pdf"

# ===== System Prompt cho PDF Reader =====
PDF_READER_SYS = (
    "B·∫°n l√† m·ªôt tr·ª£ l√Ω AI chuy√™n ƒë·ªçc t√†i li·ªáu PDF ƒë∆∞·ª£c cung c·∫•p v√† CH·ªà tr·∫£ l·ªùi c√°c c√¢u h·ªèi "
    "LI√äN QUAN TR·ª∞C TI·∫æP ƒë·∫øn Lu·∫≠t Lao ƒë·ªông Vi·ªát Nam.\n\n"
    "Nguy√™n t·∫Øc l√†m vi·ªác:\n"
    "1) Ph·∫°m vi: Ch·ªâ tr·∫£ l·ªùi c√¢u h·ªèi v·ªÅ Lu·∫≠t Lao ƒë·ªông Vi·ªát Nam v√† c√°c quy ƒë·ªãnh trong t√†i li·ªáu PDF. "
    "N·∫øu c√¢u h·ªèi kh√¥ng li√™n quan, l·ªãch s·ª± t·ª´ ch·ªëi: "
    "\"Xin l·ªói, t√¥i ch·ªâ h·ªó tr·ª£ n·ªôi dung li√™n quan ƒë·∫øn Lu·∫≠t Lao ƒë·ªông trong t√†i li·ªáu n√†y\".\n"
    "2) Ngu·ªìn th√¥ng tin: Ch·ªâ s·ª≠ d·ª•ng th√¥ng tin c√≥ trong PDF; kh√¥ng suy di·ªÖn hay b·ªï sung ki·∫øn th·ª©c b√™n ngo√†i. "
    "N·∫øu th√¥ng tin kh√¥ng c√≥, tr·∫£ l·ªùi nguy√™n vƒÉn: "
    "\"Th√¥ng tin n√†y kh√¥ng c√≥ trong t√†i li·ªáu ƒë∆∞·ª£c cung c·∫•p\".\n"
    "3) Ng√¥n ng·ªØ: S·ª≠ d·ª•ng vƒÉn phong chu·∫©n m·ª±c, ph√°p l√Ω, r√µ r√†ng v√† trung l·∫≠p; tr√°nh suy ƒëo√°n ho·∫∑c di·ªÖn ƒë·∫°t thi·∫øu ch√≠nh x√°c.\n"
    "4) Tr√¨nh b√†y: Gi·∫£i th√≠ch m·∫°ch l·∫°c, h·ªá th·ªëng; khi ph√π h·ª£p h√£y li·ªát k√™ c√°c √Ω ch√≠nh. "
    "N·∫øu c√≥ th·ªÉ, n√™u r√µ s·ªë ƒëi·ªÅu, kho·∫£n, m·ª•c ho·∫∑c s·ªë trang trong PDF.\n"
    "5) B√†i t·∫≠p & ng·ªØ ph√°p (ch·ªâ khi g·∫Øn v·ªõi n·ªôi dung Lu·∫≠t Lao ƒë·ªông trong t√†i li·ªáu):\n"
    "   - B√†i t·∫≠p: gi·∫£i th√≠ch chi ti·∫øt t·ª´ng b∆∞·ªõc d·ª±a tr√™n n·ªôi dung PDF.\n"
    "   - Ng·ªØ ph√°p: gi·∫£i th√≠ch quy t·∫Øc v√† ƒë∆∞a v√≠ d·ª• tr√≠ch t·ª´ ph·∫ßn quy ƒë·ªãnh trong t√†i li·ªáu.\n"
    "6) Ng·ªØ c·∫£nh: S·ª≠ d·ª•ng l·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán ƒë·ªÉ hi·ªÉu r√µ c√¢u h·ªèi nh∆∞ng lu√¥n tu√¢n th·ªß ph·∫°m vi tr√™n.\n"
    "7) Tr∆∞·ªùng h·ª£p m∆° h·ªì: Y√™u c·∫ßu ng∆∞·ªùi d√πng l√†m r√µ ƒë·ªÉ b·∫£o ƒë·∫£m c√¢u tr·∫£ l·ªùi ch√≠nh x√°c, ph√π h·ª£p v·ªõi t√†i li·ªáu.\n\n"
    "M·ª•c ti√™u: Cung c·∫•p c√¢u tr·∫£ l·ªùi ch√≠nh x√°c, h·ªØu √≠ch v√† d·ªÖ hi·ªÉu v·ªÅ Lu·∫≠t Lao ƒë·ªông Vi·ªát Nam, "
    "d·ª±a ho√†n to√†n tr√™n n·ªôi dung c·ªßa t√†i li·ªáu PDF ƒë∆∞·ª£c cung c·∫•p."
)

def build_context_from_hits(hits, max_chars: int = 6000) -> str:
    """Gh√©p c√°c ƒëo·∫°n tr√≠ch cho LLM, gi·ªõi h·∫°n ƒë·ªô d√†i ƒë·ªÉ tr√°nh v∆∞·ª£t context."""
    ctx = []
    total = 0
    for idx, h in enumerate(hits, start=1):
        seg = f"[{idx}] {h.page_content.strip()}"
        if total + len(seg) > max_chars:
            break
        ctx.append(seg)
        total += len(seg)
    return "\n\n".join(ctx)

def check_vectordb_exists() -> bool:
    """Ki·ªÉm tra xem vectorDB ƒë√£ c√≥ d·ªØ li·ªáu ch∆∞a"""
    try:
        # Th·ª≠ search m·ªôt t·ª´ b·∫•t k·ª≥ ƒë·ªÉ ki·ªÉm tra
        test_results = vectordb.similarity_search("test", k=1)
        return len(test_results) > 0
    except Exception:
        return False

def get_vectordb_stats() -> Dict[str, Any]:
    """L·∫•y th·ªëng k√™ v·ªÅ vectorDB"""
    try:
        # L·∫•y collection ƒë·ªÉ ki·ªÉm tra s·ªë l∆∞·ª£ng documents
        collection = vectordb._collection
        count = collection.count()
        return {
            "total_documents": count,
            "path": VECTORDB_PATH,
            "exists": count > 0
        }
    except Exception as e:
        return {
            "total_documents": 0,
            "path": VECTORDB_PATH,
            "exists": False,
            "error": str(e)
        }

def ingest_pdf():
    """ƒê·ªçc v√† ƒë∆∞a PDF v√†o VectorDB"""
    new_docs: List[Document] = []
    try:
        # Ki·ªÉm tra file t·ªìn t·∫°i
        if not os.path.exists(PDF_PATH):
            print(f" Kh√¥ng t√¨m th·∫•y file PDF: {PDF_PATH}")
            return False
            
        print(f"üìñ ƒêang ƒë·ªçc file PDF: {os.path.basename(PDF_PATH)}")
        b = read_pdf_bytes_from_path(PDF_PATH)
        text = extract_pdf_text(b)
        
        if not text.strip():
            print(f"Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c n·ªôi dung t·ª´ PDF: {PDF_PATH}")
            return False
            
        print(" ƒêang chia text th√†nh c√°c chunks...")
        chunks = chunk_text(text)
        
        print(f"T·∫°o {len(chunks)} documents...")
        for i, ch in enumerate(chunks):
            new_docs.append(Document(
                page_content=ch,
                metadata={"source": PDF_PATH, "chunk": i, "total_chunks": len(chunks)}
            ))
            
        if new_docs:
            print(" ƒêang l∆∞u v√†o VectorDB...")
            vectordb.add_documents(new_docs)
            print(f"ƒê√£ n·∫°p {len(new_docs)} ƒëo·∫°n t·ª´ PDF v√†o VectorDB")
            print(f"VectorDB ƒë∆∞·ª£c l∆∞u t·∫°i: {VECTORDB_PATH}")
            return True
        else:
            print(f" Kh√¥ng c√≥ n·ªôi dung ƒë·ªÉ n·∫°p t·ª´ PDF")
            return False
            
    except Exception as e:
        print(f"L·ªói khi x·ª≠ l√Ω PDF {PDF_PATH}: {e}")
        return False

def clear_vectordb():
    """X√≥a to√†n b·ªô d·ªØ li·ªáu trong vectorDB"""
    try:
        # X√≥a collection hi·ªán t·∫°i
        vectordb._collection.delete()
        print("ƒê√£ x√≥a to√†n b·ªô d·ªØ li·ªáu trong VectorDB")
        return True
    except Exception as e:
        print(f" L·ªói khi x√≥a VectorDB: {e}")
        return False

_URL_RE = re.compile(r"https?://[^\s]+", re.IGNORECASE)

def clean_question_remove_uris(text: str) -> str:
    """Lo·∫°i b·ªè c√°c URL v√† path .pdf ra kh·ªèi c√¢u h·ªèi tr∆∞·ªõc khi ƒë∆∞a v√†o retriever."""
    txt = _URL_RE.sub(" ", text or "")
    toks = re.split(r"\s+", txt)
    toks = [t for t in toks if not t.lower().endswith(".pdf")]
    txt = " ".join(toks)
    return re.sub(r"\s+", " ", txt).strip()

def process_pdf_question(i: Dict[str, Any]) -> str:
    """X·ª≠ l√Ω c√¢u h·ªèi v·ªÅ PDF"""
    message = i["message"]
    history: List[BaseMessage] = i.get("history", [])

    # Ki·ªÉm tra v√† n·∫°p PDF n·∫øu c·∫ßn
    if not check_vectordb_exists():
        print("VectorDB tr·ªëng, ƒëang n·∫°p PDF v√†o h·ªá th·ªëng...")
        if not ingest_pdf():
            return "Xin l·ªói, t√¥i g·∫∑p l·ªói khi n·∫°p t√†i li·ªáu PDF. Vui l√≤ng th·ª≠ l·∫°i."

    # L√†m s·∫°ch c√¢u h·ªèi
    clean_question = clean_question_remove_uris(message)
    
    # T√¨m ki·∫øm trong vectordb
    try:
        hits = retriever.invoke(clean_question)
        if not hits:
            return "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong t√†i li·ªáu PDF ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa b·∫°n."
        
        # X√¢y d·ª±ng context t·ª´ c√°c ƒëo·∫°n t√¨m ƒë∆∞·ª£c
        context = build_context_from_hits(hits, max_chars=6000)
        
        # T·∫°o messages ƒë·ªÉ g·ª≠i cho LLM
        messages = [SystemMessage(content=PDF_READER_SYS)]
        
        # Th√™m l·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán
        if history:
            messages.extend(history[-10:]) 
        # Th√™m c√¢u h·ªèi hi·ªán t·∫°i v·ªõi context
        user_message = f"""C√¢u h·ªèi: {clean_question}

N·ªôi dung li√™n quan t·ª´ t√†i li·ªáu PDF:
{context}

H√£y tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n n·ªôi dung t√†i li·ªáu tr√™n."""

        messages.append(HumanMessage(content=user_message))
        
        # G·ªçi LLM ƒë·ªÉ tr·∫£ l·ªùi
        response = llm.invoke(messages).content
        
        # Th√™m th√¥ng tin ngu·ªìn
        source_info = f"\n\n_Ngu·ªìn: {os.path.basename(PDF_PATH)}_"
        
        return response + source_info
        
    except Exception as e:
        return f"Xin l·ªói, t√¥i g·∫∑p l·ªói khi x·ª≠ l√Ω c√¢u h·ªèi: {str(e)}"

# ===== Main Chain =====
pdf_chain = RunnableLambda(process_pdf_question)

# ===== Memory wrapper =====
store: Dict[str, ChatMessageHistory] = {}

def get_history(session_id: str):
    if session_id not in store: 
        store[session_id] = ChatMessageHistory()
    return store[session_id]

chatbot = RunnableWithMessageHistory(
    pdf_chain,
    get_history,
    input_messages_key="message",
    history_messages_key="history"
)

def print_help():
    """In ra danh s√°ch c√°c l·ªánh c√≥ s·∫µn"""
    print("\n C√°c l·ªánh c√≥ s·∫µn:")
    print("  - 'exit' ho·∫∑c 'quit': Tho√°t ch∆∞∆°ng tr√¨nh")
    print("  - 'clear': X√≥a l·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán")
    print("  - 'reload': N·∫°p l·∫°i PDF v√†o h·ªá th·ªëng")
    print("  - 'status': Ki·ªÉm tra tr·∫°ng th√°i VectorDB")
    print("  - 'reset': X√≥a VectorDB v√† n·∫°p l·∫°i t·ª´ ƒë·∫ßu")
    print("  - 'help': Hi·ªÉn th·ªã danh s√°ch l·ªánh n√†y")

def handle_command(command: str, session: str) -> bool:
    """X·ª≠ l√Ω c√°c l·ªánh ƒë·∫∑c bi·ªát. Tr·∫£ v·ªÅ True n·∫øu c·∫ßn ti·∫øp t·ª•c, False n·∫øu tho√°t"""
    global vectordb, retriever
    
    command = command.lower().strip()
    
    if command in {"exit", "quit"}:
        print("T·∫°m bi·ªát!")
        return False
        
    elif command == "clear":
        if session in store:
            store[session].clear()
            print(" ƒê√£ x√≥a l·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán.\n")
        return True
        
    elif command == "reload":
        print("ƒêang n·∫°p l·∫°i PDF...")
        if ingest_pdf():
            print("ƒê√£ n·∫°p l·∫°i PDF th√†nh c√¥ng!\n")
        else:
            print("L·ªói khi n·∫°p l·∫°i PDF\n")
        return True
        
    elif command == "status":
        stats = get_vectordb_stats()
        if stats["exists"]:
            print(f"VectorDB c√≥ {stats['total_documents']} documents")
            print(f" ƒê∆∞·ªùng d·∫´n: {stats['path']}")
            print(f" File PDF: {os.path.basename(PDF_PATH)}")
        else:
            print(" VectorDB tr·ªëng ho·∫∑c ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o")
            if "error" in stats:
                print(f"Chi ti·∫øt: {stats['error']}")
        print()
        return True
        
    elif command == "reset":
        print("ƒêang x√≥a VectorDB hi·ªán t·∫°i...")
        if clear_vectordb():
            print("ƒêang n·∫°p l·∫°i PDF t·ª´ ƒë·∫ßu...")
            # T·∫°o l·∫°i vectordb
            vectordb = Chroma(
                embedding_function=emb,
                persist_directory=VECTORDB_PATH
            )
            retriever = vectordb.as_retriever(search_kwargs={"k": 5})
            
            if ingest_pdf():
                print("ƒê√£ reset v√† n·∫°p l·∫°i PDF th√†nh c√¥ng!\n")
            else:
                print(" L·ªói khi n·∫°p l·∫°i PDF sau reset\n")
        else:
            print(" L·ªói khi reset VectorDB\n")
        return True
        
    elif command == "help":
        print_help()
        return True
        
    else:
        return True  

# ===== CLI Interface =====
if __name__ == "__main__":
    session = "pdf_reader_session"
    
    print("=" * 60)
    print("CHATBOT V·ªÄ Lu·∫≠t lao ƒë·ªông")
    print("=" * 60)
    print(f"T√†i li·ªáu: {os.path.basename(PDF_PATH)}")
    print(f"VectorDB: {VECTORDB_PATH}")
    print("T√¥i ch·ªâ tr·∫£ l·ªùi c√°c c√¢u h·ªèi v·ªÅ Lu·∫≠t lao ƒë·ªông")
    
    print_help()
    print("=" * 60)
    
    # Ki·ªÉm tra v√† n·∫°p PDF n·∫øu c·∫ßn
    if check_vectordb_exists():
        stats = get_vectordb_stats()
        print(f"VectorDB ƒë√£ c√≥ {stats['total_documents']} documents, s·∫µn s√†ng tr·∫£ l·ªùi!\n")
    else:
        print(" ƒêang n·∫°p t√†i li·ªáu PDF l·∫ßn ƒë·∫ßu...")
        if ingest_pdf():
            print(" S·∫µn s√†ng tr·∫£ l·ªùi c√¢u h·ªèi!\n")
        else:
            print("Kh√¥ng th·ªÉ n·∫°p PDF. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n file.\n")
    
    # Main conversation loop
    while True:
        try:
            message = input(" B·∫°n: ").strip()
            
            if not message:
                print("  Vui l√≤ng nh·∫≠p c√¢u h·ªèi ho·∫∑c l·ªánh.\n")
                continue
            
            # X·ª≠ l√Ω l·ªánh ƒë·∫∑c bi·ªát
            if not handle_command(message, session):
                break  
                
            # N·∫øu kh√¥ng ph·∫£i l·ªánh ƒë·∫∑c bi·ªát, x·ª≠ l√Ω nh∆∞ c√¢u h·ªèi
            if message.lower() not in ["clear", "reload", "status", "reset", "help"]:
                print(" ƒêang t√¨m ki·∫øm trong t√†i li·ªáu...")
                
                try:
                    response = chatbot.invoke(
                        {"message": message}, 
                        config={"configurable": {"session_id": session}}
                    )
                    print(f"\n Bot: {response}\n")
                    print("-" * 60 + "\n")
                except Exception as e:
                    print(f" L·ªói khi x·ª≠ l√Ω c√¢u h·ªèi: {e}\n")
            
        except KeyboardInterrupt:
            print("\n T·∫°m bi·ªát!")
            break
        except EOFError:
            print("\nT·∫°m bi·ªát!")
            break
        except Exception as e:
            print(f" L·ªói kh√¥ng mong mu·ªën: {e}\n")